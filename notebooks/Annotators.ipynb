{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c583c9",
   "metadata": {},
   "source": [
    "# TEXTUAL ANNOTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293521f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # For REST calls\n",
    "import json # for modelling objects in the JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa839c",
   "metadata": {},
   "source": [
    "Now open the file config.json, which contains the key required for making REST requests to the SoBigData server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b041d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line opens the file from the file system, the file is in the same folder of the notebook and it is opened in \"read-only mode\"\n",
    "with open(\"../config.json\", 'r') as json_file:\n",
    "    config = json.load(json_file) # load the json object inside the config file\n",
    "    KEY = config['d4science_KEY'] # this is the key we will be using for REST calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87ec817",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGME_ENDPOINT = \"https://tagme.d4science.org/tagme/tag\"\n",
    "LANG = \"en\" # Also works in italian and german"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc017c",
   "metadata": {},
   "source": [
    "Now create the function that will \"wrap\" the REST call. It needs a textual input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225be2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tagme(text):\n",
    "    payload = {\"text\": text, \"gcube-token\": KEY, \"lang\": LANG}\n",
    "    # Now we issue a post HTTP request\n",
    "    r = requests.post(TAGME_ENDPOINT, payload)\n",
    "    if r.status_code != 200:\n",
    "        # this means something went wrong with the query\n",
    "        raise Exception(\"Error on text: {}\\n{}\".format(text, r.text))\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d255a5b",
   "metadata": {},
   "source": [
    "And now we display the result for a simple textual query. The interesting part, for us, is under the key _annotations_.\n",
    "This will be a list of annotations containing the following fields:\n",
    "- **spot (string)**: how the anchor appears in the text.\n",
    "- **start (int)**: the index of the starting character of the anchor.\n",
    "- **end (int)**: the index of the ending character of the anchor.\n",
    "- **link_probability (float ‚àà[ùüé,ùüè])**: number of times that the spot is an anchor in Wikipedia / number of occurrences of the spot in Wikipedia.\n",
    "- **rho (float ‚àà[ùüé,ùüè])**: semantic coherency of the entity with respect to the query.\n",
    "- **id (int)**: the Wikipedia identifier of the page _(https://en.wikipedia.org/?curid=<>)_.\n",
    "- **title (string)**: title of the Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c867c7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': '5',\n",
       " 'annotations': [{'spot': 'Italy',\n",
       "   'start': 0,\n",
       "   'link_probability': 0.4437723457813263,\n",
       "   'rho': 0.4525856375694275,\n",
       "   'end': 5,\n",
       "   'id': 362466,\n",
       "   'title': 'Italy national football team'},\n",
       "  {'spot': 'will',\n",
       "   'start': 6,\n",
       "   'link_probability': 0.0036389119923114777,\n",
       "   'rho': 0.06729841977357864,\n",
       "   'end': 10,\n",
       "   'id': 32828260,\n",
       "   'title': 'Will (2011 film)'},\n",
       "  {'spot': '2022 world cup',\n",
       "   'start': 35,\n",
       "   'link_probability': 0.3492063581943512,\n",
       "   'rho': 0.3398236632347107,\n",
       "   'end': 49,\n",
       "   'id': 17742072,\n",
       "   'title': '2022 FIFA World Cup'}],\n",
       " 'time': 30,\n",
       " 'api': 'tag',\n",
       " 'lang': 'en',\n",
       " 'timestamp': '2023-12-04T14:47:42'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_text = \"Italy will not be competing in the 2022 world cup\"\n",
    "resp = query_tagme(short_text)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c21bd",
   "metadata": {},
   "source": [
    "## Handle longer texts / filtering noisy annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298ffde",
   "metadata": {},
   "source": [
    "TagME has been designed for handling short texts, but we also have a way to obtain competitive results on longer ones. \n",
    "This requires modifying the window of spots that are checked by TagME when doing disambiguation.\n",
    "\n",
    "Now open a new text file with a slightly longer text and annotate it with TagME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39f92ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Leonardo da Vinci was an Italian Renaissance polymath whose areas of interest included invention, painting, sculpting, architecture, science, music, mathematics, engineering, literature, anatomy, geology, astronomy, botany, writing, history, and cartography. \\nHe has been variously called the father of palaeontology, ichnology, and architecture, and is widely considered one of the greatest painters of all time. Leonardo is revered for his technological ingenuity. He conceptualised flying machines, a type of armoured fighting vehicle, concentrated solar power, an adding machine, and the double hull.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/Leonardo.txt\", 'r') as long_file:\n",
    "    # the text is not a json object, it is just a plaintext, so just read it regularly with read()\n",
    "    text = long_file.read()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d3357",
   "metadata": {},
   "source": [
    "Now we will change the tagging function we made before, by adding an optional boolean parameter. If true, this means that the text is long, otherwise it is short and we can avoid changing the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de1b9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tagme(text, long_text=False):\n",
    "    payload = {\"text\": text, \"gcube-token\": KEY, \"lang\": LANG}\n",
    "    if long_text:\n",
    "        # long_text is by defaul false, but if specified by the user, we set the window size at 5\n",
    "        payload[\"long_text\"] = 5\n",
    "    r = requests.post(TAGME_ENDPOINT, payload)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(\"Error on text: {}\\n{}\".format(text, r.text))\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7dc7f",
   "metadata": {},
   "source": [
    "But how do we deal with noisy annotations? TagME gives us a \"content relevance\" score in the form of the **Rho-score**.\n",
    "We can filter the lowest ranked annotations on relevancy to remove noise. A common threshold for this task is 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e8f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try changing the min_rho parameter and see how it impacts the returned entities\n",
    "def get_tagme_entities(tagme_response, min_rho=0.3):\n",
    "    ann = tagme_response[\"annotations\"]\n",
    "    ann = [a for a in ann if a[\"rho\"] > min_rho] # filter all the annotations with a rho score lower than the threshold\n",
    "    return [a[\"title\"] for a in ann if \"title\" in a] # return just the page titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1799d1a",
   "metadata": {},
   "source": [
    "Now see which entities _disappear_ when filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02b543b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE FILTERING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Leonardo da Vinci',\n",
       " 'Leonardo da Vinci',\n",
       " 'Italian Renaissance',\n",
       " 'Polymath',\n",
       " 'Attention',\n",
       " 'Invention',\n",
       " 'Painting',\n",
       " 'Sculpture',\n",
       " 'Architecture',\n",
       " 'Science',\n",
       " 'Music and mathematics',\n",
       " 'Engineering',\n",
       " 'Literature',\n",
       " 'Anatomy',\n",
       " 'Geology',\n",
       " 'Astronomy',\n",
       " 'Botany',\n",
       " 'Writing',\n",
       " 'History',\n",
       " 'Cartography',\n",
       " 'Clergy',\n",
       " 'Paleontology',\n",
       " 'Ichnology',\n",
       " 'Architecture',\n",
       " 'Neoplatonism',\n",
       " 'Greatest!',\n",
       " 'Painting',\n",
       " 'Time (magazine)',\n",
       " 'Leonardo da Vinci',\n",
       " 'Canonization',\n",
       " 'Technology',\n",
       " 'Ingenuity',\n",
       " 'Concept',\n",
       " 'Flying Machines s.r.o.',\n",
       " 'Granite',\n",
       " 'Stellar classification',\n",
       " 'Armoured fighting vehicle',\n",
       " 'Concentrated solar power',\n",
       " 'Adding machine',\n",
       " 'Double hull']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"BEFORE FILTERING\")\n",
    "resp = query_tagme(text, long_text=True) \n",
    "before_filtering = [a[\"title\"] for a in resp['annotations'] if \"title\" in a]\n",
    "before_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6fe3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER FILTERING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Leonardo da Vinci',\n",
       " 'Leonardo da Vinci',\n",
       " 'Italian Renaissance',\n",
       " 'Polymath',\n",
       " 'Music and mathematics',\n",
       " 'Geology',\n",
       " 'Astronomy',\n",
       " 'Botany',\n",
       " 'Cartography',\n",
       " 'Paleontology',\n",
       " 'Ichnology',\n",
       " 'Armoured fighting vehicle',\n",
       " 'Concentrated solar power',\n",
       " 'Adding machine']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"AFTER FILTERING\")\n",
    "after_filtering = get_tagme_entities(resp)\n",
    "after_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f04019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The annotations that were filtered out are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Attention',\n",
       " 'Invention',\n",
       " 'Painting',\n",
       " 'Sculpture',\n",
       " 'Architecture',\n",
       " 'Science',\n",
       " 'Engineering',\n",
       " 'Literature',\n",
       " 'Anatomy',\n",
       " 'Writing',\n",
       " 'History',\n",
       " 'Clergy',\n",
       " 'Architecture',\n",
       " 'Neoplatonism',\n",
       " 'Greatest!',\n",
       " 'Painting',\n",
       " 'Time (magazine)',\n",
       " 'Canonization',\n",
       " 'Technology',\n",
       " 'Ingenuity',\n",
       " 'Concept',\n",
       " 'Flying Machines s.r.o.',\n",
       " 'Granite',\n",
       " 'Stellar classification',\n",
       " 'Double hull']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The annotations that were filtered out are:\")\n",
    "[a for a in before_filtering if a not in after_filtering]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a5a82",
   "metadata": {},
   "source": [
    "# RELATEDNESS\n",
    "Ok but now that I have entities, how do I deal with them? I need to know which are similar and which are not.\n",
    "If we don't see any way of \"dealing with the entities\", how do we unlock its full potential? How is this method more powerful than dealing with generic words as tokens?\n",
    "\n",
    "There are several ways in which we can obtain the relatedness of couples of entities.\n",
    "The main one that is shown in this notebook is by querying TagME itself. TagME has an internal relatedness computation framework, so I can ask TagME itself how close two entities are to one another. This metric is computed directly on the Wikipedia Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82829fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The URL where the relatedness is given\n",
    "ENDPOINT_RELATEDNESS = \"https://tagme.d4science.org/tagme/rel\"\n",
    "\n",
    "# In case I need efficiency I can do batch queries of 100 couples per HTTP call\n",
    "def query_relatedness(e1, e2):\n",
    "    # Entities require underscores in-place of the spaces. The space is between entity one and entity two\n",
    "    tt = e1.replace(\" \", \"_\") + \" \" + e2.replace(\" \", \"_\")\n",
    "    payload = {\"tt\": tt, \"gcube-token\": KEY, \"lang\": LANG}\n",
    "    r = requests.post(ENDPOINT_RELATEDNESS, payload)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(\"Error on relatedness computation: {}\\n{}\".format(tt, r.text))\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c65cb4",
   "metadata": {},
   "source": [
    "Now let's test the relatedness of three entities. \n",
    "Two are closely related to one-another (biology and biotechnology).\n",
    "The last one is completely out of context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e252769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'couple': 'Biology Biotechnology', 'rel': 0.6070536971092224}]\n",
      "[{'couple': 'Barack_Obama Biotechnology', 'rel': 0.23863035440444946}]\n",
      "[{'couple': 'Barack_Obama Biology', 'rel': 0.16491788625717163}]\n"
     ]
    }
   ],
   "source": [
    "first = query_relatedness(\"Biology\", \"Biotechnology\")\n",
    "second = query_relatedness(\"Barack Obama\", \"Biotechnology\")\n",
    "thirds = query_relatedness(\"Barack Obama\", \"Biology\")\n",
    "print(first['result'])\n",
    "print(second['result'])\n",
    "print(thirds['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c226b66ad212a3c8eabd6b6be3829f40d39277fa7bdc3bf63a77768ea80548ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
